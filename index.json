[{"authors":["admin"],"categories":null,"content":"I am interested in the development, evaluation, and application of phylogenetic methods, using Bayesian statistics as an overarching framework and fossil as well as extant vertebrates as my primary model system. My current research projects include the development of a fast and flexible Bayesian method for estimating time-scaled supertrees, and an empirical study assessing the ability of environment-dependent birth-death models to yield insights into the diversification of coevolving clades.\nIn 2024, I completed my PhD in Geophysical Sciences at the University of Chicago, where I worked in the Slater Lab on fossil vertebrate phylogenetics and macroevolution. My previous research experience includes paleontological and ecological fieldwork in Poland and French Polynesia, a bioinformatics internship in the Kondrashov Lab at the Centre de Regulació Genòmica in Barcelona, Spain, and undergraduate research in the Alfaro Lab at UCLA.\n","date":1730075400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1730075400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am interested in the development, evaluation, and application of phylogenetic methods, using Bayesian statistics as an overarching framework and fossil as well as extant vertebrates as my primary model system. My current research projects include the development of a fast and flexible Bayesian method for estimating time-scaled supertrees, and an empirical study assessing the ability of environment-dependent birth-death models to yield insights into the diversification of coevolving clades.\nIn 2024, I completed my PhD in Geophysical Sciences at the University of Chicago, where I worked in the Slater Lab on fossil vertebrate phylogenetics and macroevolution.","tags":null,"title":"David Černý","type":"authors"},{"authors":["David Černý"],"categories":["RevBayes"],"content":" Introduction In the fall of 2022, I got to TA a course called Phylogenetics and the Fossil Record, taught by my PhD advisor, Graham Slater. Although I TA\u0026rsquo;ed almost every single quarter during my time at the University of Chicago, this particular experience was pretty unique, for a number of reasons. First, it was a mixed undergraduate/graduate course, whereas all the other courses I TA\u0026rsquo;ed were offered exclusively to undergrads, and often specifically to non-science majors. Second, it was the only course I ever TA\u0026rsquo;ed that was directly and specifically related to my own research interests. Third, and related to the previous point, my responsibilities went a little further than they usually would. I wasn\u0026rsquo;t just in charge of grading and leading discussion or problem-set sessions: I was responsible for running a weekly two-hour lab where the students would get some hands-on practice with the material they\u0026rsquo;d learned about in their lectures, and Graham gave me a lot of freedom when it came to deciding how these labs should be organized and crafting the relevant exercises. This freedom extended to the choice of the software to be used; more on that below. Despite Graham\u0026rsquo;s and my best efforts, we had to make some adjustments to the originally planned course schedule, so on a few occasions, I even ended up having to introduce foundational concepts in advance of the corresponding lectures, such as the theory behind MCMC.\nIn contrast to molecular phylogenetics, where there is little interest in individual characters (at the end of the day, a nucleotide is a nucleotide) and dataset assembly is typically automated to a much greater extent, morphological phylogenetics places a lot more emphasis on the process of creating the dataset by scoring features that exhibit informative variation.1 Therefore, the very first lab of the course was devoted precisely to this process, with a fun spin: Graham had students assemble their own character matrices for several different types of pasta, with orzo as the outgroup.0\nThis was a really cool way of showing the students how morphological phylogenetic datasets are assembled, and teaching them about the importance of character coding, with great discussions taking place in different breakout groups about whether a given character should be treated as discrete or continuous, ordered or unordered, etc. I felt a little more ambivalent about our decision to stick with the pasta toy example for the rest of the course: every time a new method was introduced, the corresponding homework assignment would have the students apply it to their own pasta dataset. This worked great for parsimony, where you can have a lot of fun with inferring synapomorphies for particular nodes (extreme elongation evolving in the last common ancestor of spaghetti and linguine, etc.), but it got a little too cutesy for its own good when we got to tip-dating, which involves quantities like fossil ages and extinction rates that have no reasonable interpretation unless you are dealing with things that actually die out at different points in time and leave behind remains, like biological species or languages. In this latter case, I found it easier to have the students analyze a real dataset. Graham picked the one from Tedford et al.\u0026rsquo;s (2009) analysis of North American canids for this purpose, which I also used as an example when demoing the different methods.\nBefore each lab, I would upload a PDF \u0026ldquo;handout\u0026rdquo; to Canvas for the students to read prior to our meeting, though this wasn\u0026rsquo;t essential, and remained mostly aspirational anyway. The handout would explain key concepts and show how to implement them in the program we were about to work with, and I would use it as a guide for our lab activity. Interspersed throughout the handout, there would be exercises that the students were supposed to complete on their own and turn in the following week \u0026ndash; usually, these would ask them to modify the provided code in some way, if only to run it on their own dataset. The idea behind explaining every line of code in detail was to allow the students to refer back to the handout as they were working their way through the exercises.\nChoice of software As with many similar courses, we covered the three main contemporary methods for inferring phylogenies from discrete characters, i.e., parsimony, maximum likelihood, and Bayesian inference. Unlike the other two methods, maximum likelihood is seldom used in fossil phylogenetics, so one could perhaps feel justified in skipping it, but from a pedagogical standpoint, it represents a very convenient bridge between parsimony (given their shared goal of optimizing a particular criterion, accomplished in practice by heuristic searches of tree space) and Bayesian inference (given their shared reliance on the likelihood function). Back in 2020, when the course was TA\u0026rsquo;ed by my former colleague Anna Wisniewski, PAUP* was used for parsimony, RAxML for maximum likelihood, MrBayes for time-free Bayesian inference, and BEAST 2 for tip-dating. Two years later, some changes to this list were in order. RAxML was always rather inflexible when dealing with morphological data, and by 2022, it had become legacy software \u0026ndash; no longer under active development, and replaced by RAxML-NG. The latter program has many features to commend it, and I\u0026rsquo;ve happily used it myself for combined analyses of molecular and morphological data, but it unfortunately doesn\u0026rsquo;t implement a substitution model for ordered characters out of the box. (The old RAxML did implement it, but incorrectly.) I\u0026rsquo;m sure this feature is only missed by a tiny percentage of RAxML-NG users, and you can apparently get around its absence by manually specifying the appropriate instantaneous rate matrix yourself, which is the same way ordered characters had to be handled in BEAST 2 when I last used it (though in RAxML-NG, this can apparently lead to some pesky underflow issues). However, when analyzing real-world morphological data, being able to treat some but not all multistate characters as ordered is kind of a big deal, so I designed the maximum-likelihood lab around IQ-TREE, which makes this easy (with one important caveat; see below) and which I already had experience applying to morphological data as part of the analyses that ended up published as Černý \u0026amp; Simonoff (2023).\nWith regard to Bayesian inference, it seemed like overkill to me to introduce a new program every week, especially since the learning curve tends to be quite steep for each one of them. MrBayes had two important advantages: it can do both time-free inference and tip-dating, and the analysis setup (by means of setting a limited number of predefined parameters either interactively or in a separate block at the end of one\u0026rsquo;s Nexus file) resembles PAUP* quite a bit, allowing the students to build on what they learned earlier in the course. However, like RAxML, MrBayes is legacy software, which is both a blessing and a curse. It means that it is perhaps less likely to crash with a cryptic error message than competing programs like BEAST 2 and RevBayes, which are under active development and which allow users to freely assemble their own models by mixing and matching a large number of building blocks. However, it also means that things that were once supposed to work no longer do: as I recently found out, MrBayes can\u0026rsquo;t be used together with the BEAGLE library on ARM64 processors, which was not a concern in 2012 when the last minor release (3.2) came out, but which is a concern now that Apple has switched to this architecture for its laptops and desktops. Most importantly, it simply means that the program will be less and less useful going forward, as users increasingly abandon it for exciting new models and features implemented elsewhere.\nIn contrast, BEAST is a mature piece of software which is nevertheless still under active development, and which even comes with a GUI called BEAUti that should, in theory, make it much easier to use than the alternatives. Unfortunately, by design, BEAST only infers time trees, so it doesn\u0026rsquo;t support the full range of use cases we wanted to cover in the course. Moreover, my personal impression is that the GUI doesn\u0026rsquo;t quite live up to its promise. In my own BEAST 2 tip-dating analyses, I always found it necessary to go back to the XML that BEAUti generated for me and edit it manually (e.g., to treat certain characters as ordered, as mentioned above), which could be quite intimidating. A BEAST XML can be a beast of a file (easily reaching several megabytes in size when setting up total-evidence analyses that include molecular alignments), and it doesn\u0026rsquo;t clearly separate the data from the modeling choices (priors and parameters) and inference settings (sampler type, chain length, logging options, etc.). The BEAST 2 development team seems to be well aware of these problems, as shown by their recent proposal for a high-level model specification language called LinguaPhylo (Drummond et al. 2023), and by a recently circulated survey raising the prospect of a backward-incompatible \u0026ldquo;BEAST 3\u0026rdquo; that entirely abandons the XML format in favor of such a language. Of note here is the fact LinguaPhylo is markedly similar to Rev, the model specification language used by RevBayes, so for now, the simplest solution is perhaps to use the latter program.\nIndeed, in the fall of 2022, RevBayes seemed like the logical choice for the course Graham and I wanted to teach. Unlike BEAST, RevBayes can handle time-free inference as well as tip-dating, and unlike MrBayes, it is under active, community-driven development. It also helped that by the time I was asked to TA Phylogenetics and the Fossil Record, I\u0026rsquo;d already had some \u0026ndash; though still quite rudimentary \u0026ndash; experience as a RevBayes developer: I had implemented a new supertree method in it for chapter 1 of my dissertation, and was slowly becoming familiar enough with the code base to start contributing bug fixes. What sealed the deal was the fact that after covering tree estimation in detail, we planned to dedicate the last lab of the course to things one can do with trees, such as trait evolution and/or biogeography. Unlike MrBayes and BEAST, which are narrowly focused on phylogenetic inference and would require us to switch to yet another piece of software (perhaps R packages such as geiger or BioGeoBEARS) for this one last lab, RevBayes tries to be a one-stop shop for everything phylogenetic, and provides a framework that is general enough to make such analyses possible. The undoubtedly not-so-easy effort of learning how to use RevBayes would pay off, because once the program was introduced, the students could just keep using it for everything we were about to throw at them.\nOr at least, that was the idea; the final lab never actually took place. In part, that was because I realized (more on that below) that I had to dedicate an entire lab to introducing the basics of how RevBayes works, before getting around to using it for tree inference. I can see how this might seem ironic, and as an admission that RevBayes was more trouble than it\u0026rsquo;s worth in the end. However, I don\u0026rsquo;t feel too bad about it: we were already falling behind the schedule in general, including with the lectures, so it\u0026rsquo;s not like the extra lab held up the whole course and made it impossible to cover material that would have been covered otherwise.\nTeaching RevBayes Once the decision was made to go with RevBayes for the Bayesian labs, my initial plan was to start with Tracy Heath\u0026rsquo;s archery tutorial, which had constituted my own introduction to RevBayes back in the halcyon days of October 2018. Fortunately, I had the good sense to ask for recommendations in the RevBayes developer Slack, and immediately received excellent advice, tips, and suggestions from Jeremy Brown, Jiansi Gao, Bruno Petrucci, Orlando Schwery, Carrie Tribble, Rachel Warnock, and April Wright \u0026ndash; it really drove home the value of using software that has a lively, engaged developer community behind it. A number of people kindly shared their own lecture and workshop slides with me, many of which I shamelessly copied (with acknowledgments, of course \u0026ndash; see the blue text in the handouts below). Even more importantly, I was able to rely on the experience of people who had taught RevBayes to undergrads and grad students before, and prepare myself for those aspects of the process that were most likely to pose difficulties. One piece of feedback that pretty much everyone agreed on was that the archery tutorial was still a little too advanced to serve as a general introduction to RevBayes, and that my original idea of trying to keep things simple by not going into the distinction between constant, deterministic, and stochastic variables (as well as their respective assignment operators, \u0026lt;-, :=, and ~) was misguided. On the contrary, the best way forward was to spend as much time as necessary on these seeming details to make sure that the students were comfortable both with the underlying concepts from probability theory, and with representing them using the Rev syntax. In fact, the best approach would be to teach Rev much as one would any other programming language, introducing the key pieces of syntax one by one. It was for this reason that I decided to alter the original lab schedule and spend one entire meeting introducing Rev as gently as I possibly could, giving rise to Lab 6:\n       Previous Next \u0026nbsp; \u0026nbsp;   /   [pdf]   View the PDF file here.  (function(){ var url = 'Lab6.pdf'; var hidePaginator = \"\" === \"true\"; var hideLoader = \"\" === \"true\"; var selectedPageNum = parseInt(\"\") || 1; var pdfjsLib = window['pdfjs-dist/build/pdf']; if (pdfjsLib.GlobalWorkerOptions.workerSrc == '') pdfjsLib.GlobalWorkerOptions.workerSrc = \"\\/\" + 'js/pdf-js/build/pdf.worker.js'; var pdfDoc = null, pageNum = selectedPageNum, pageRendering = false, pageNumPending = null, scale = 3, canvas = document.getElementById('pdf-canvas-a1f56680'), ctx = canvas.getContext('2d'), paginator = document.getElementById(\"pdf-paginator-a1f56680\"), loadingWrapper = document.getElementById('pdf-loadingWrapper-a1f56680'); showPaginator(); showLoader(); function renderPage(num) { pageRendering = true; pdfDoc.getPage(num).then(function(page) { var viewport = page.getViewport({scale: scale}); canvas.height = viewport.height; canvas.width = viewport.width; var renderContext = { canvasContext: ctx, viewport: viewport }; var renderTask = page.render(renderContext); renderTask.promise.then(function() { pageRendering = false; showContent(); if (pageNumPending !== null) { renderPage(pageNumPending); pageNumPending = null; } }); }); document.getElementById('pdf-pagenum-a1f56680').textContent = num; } function showContent() { loadingWrapper.style.display = 'none'; canvas.style.display = 'block'; } function showLoader() { if(hideLoader) return loadingWrapper.style.display = 'flex'; canvas.style.display = 'none'; } function showPaginator() { if(hidePaginator) return paginator.style.display = 'block'; } function queueRenderPage(num) { if (pageRendering) { pageNumPending = num; } else { renderPage(num); } } function onPrevPage() { if (pageNum = pdfDoc.numPages) { return; } pageNum++; queueRenderPage(pageNum); } document.getElementById('pdf-next-a1f56680').addEventListener('click', onNextPage); pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) { pdfDoc = pdfDoc_; var numPages = pdfDoc.numPages; document.getElementById('pdf-pagecount-a1f56680').textContent = numPages; if(pageNum  numPages) { pageNum = numPages } renderPage(pageNum); }); })();  Some observations on the handout above:\n One reason why I wasn\u0026rsquo;t too unhappy with the decision to start out slow and spend some extra time on the basics was that it allowed me to tie the lab back to Graham\u0026rsquo;s first lecture on maximum likelihood, which had also introduced the concept using coin flipping / Bernoulli trials. I liked the idea of our maximum likelihood and Bayesian inference intros mirroring each other. That said, this decision also meant that I had the students run their first MCMC analysis before the topic was covered in the lectures, and before explaining the Metropolis-Hastings algorithm in detail by implementing it step by step. From a pedagogical standpoint, this may have been less than ideal. One complication that I didn\u0026rsquo;t have to deal with (unlike some of the other developers whose advice I had sought) was prefacing my introduction to Rev with an overview of general computing concepts such as using the command line, specifying directory paths, or the differences between Unix and Windows. This was not because everyone had already had a firm grasp on these by the time they enrolled in the course; it\u0026rsquo;s just that we\u0026rsquo;d run into these difficulties earlier, when introducing other software, and at this point I was able to take it for granted that the students were already familiar with them. On a related note, I was a little worried about running RevBayes on Windows, which I knew had caused a lot of trouble at some past workshops. Fortunately, thanks to a series of PRs by Ben Redelings, this had pretty much ceased to be an issue by the time I asked the students to download the appropriate executables. In the handout, I emphasize the similarities between Rev and R, since I expected the students to be familiar with the latter \u0026ndash; most likely, from their previous classes, or at the very least, from our own use of it earlier in the course. If I were to teach the course again, I would probably also point out some commonalities between Rev and Python: e.g., the distinction between functions (func(obj)) and methods (obj.method()), or the syntax for string concatenation (dir = basedir + \u0026quot;RevBayes/Is/Awesome\u0026quot;).  The following week, it was time to introduce time-free Bayesian phylogenetic inference, but I still wanted to go over the archery tutorial first to make sure everyone understood exactly how the Metropolis-Hastings algorithm worked. This resulted in an extremely long handout, but I don\u0026rsquo;t actually remember the meeting in question feeling especially rushed; two hours were enough to cover both the archery portion and the phylogram inference portion of the lab. In any case, I hope the pedagogical benefits were worth having the handout run to 18 pages. When it comes to learning basic MCMC theory, there\u0026rsquo;s nothing quite like building a toy sampler yourself \u0026ndash; this is something that Graham impressed on me early on, since it was one of the first things he had me do as his grad student.\n       Previous Next \u0026nbsp; \u0026nbsp;   /   [pdf]   View the PDF file here.  (function(){ var url = 'Lab7.pdf'; var hidePaginator = \"\" === \"true\"; var hideLoader = \"\" === \"true\"; var selectedPageNum = parseInt(\"\") || 1; var pdfjsLib = window['pdfjs-dist/build/pdf']; if (pdfjsLib.GlobalWorkerOptions.workerSrc == '') pdfjsLib.GlobalWorkerOptions.workerSrc = \"\\/\" + 'js/pdf-js/build/pdf.worker.js'; var pdfDoc = null, pageNum = selectedPageNum, pageRendering = false, pageNumPending = null, scale = 3, canvas = document.getElementById('pdf-canvas-4b477b42'), ctx = canvas.getContext('2d'), paginator = document.getElementById(\"pdf-paginator-4b477b42\"), loadingWrapper = document.getElementById('pdf-loadingWrapper-4b477b42'); showPaginator(); showLoader(); function renderPage(num) { pageRendering = true; pdfDoc.getPage(num).then(function(page) { var viewport = page.getViewport({scale: scale}); canvas.height = viewport.height; canvas.width = viewport.width; var renderContext = { canvasContext: ctx, viewport: viewport }; var renderTask = page.render(renderContext); renderTask.promise.then(function() { pageRendering = false; showContent(); if (pageNumPending !== null) { renderPage(pageNumPending); pageNumPending = null; } }); }); document.getElementById('pdf-pagenum-4b477b42').textContent = num; } function showContent() { loadingWrapper.style.display = 'none'; canvas.style.display = 'block'; } function showLoader() { if(hideLoader) return loadingWrapper.style.display = 'flex'; canvas.style.display = 'none'; } function showPaginator() { if(hidePaginator) return paginator.style.display = 'block'; } function queueRenderPage(num) { if (pageRendering) { pageNumPending = num; } else { renderPage(num); } } function onPrevPage() { if (pageNum = pdfDoc.numPages) { return; } pageNum++; queueRenderPage(pageNum); } document.getElementById('pdf-next-4b477b42').addEventListener('click', onNextPage); pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) { pdfDoc = pdfDoc_; var numPages = pdfDoc.numPages; document.getElementById('pdf-pagecount-4b477b42').textContent = numPages; if(pageNum  numPages) { pageNum = numPages } renderPage(pageNum); }); })();  Notes:\n This is not really a pedagogical consideration, but I just really like the archery tutorial, since it does a great job of demonstrating the incredible flexibility of RevBayes. Aside from a high-level language for specifying models, the other key thing that RevBayes provides to the user is an efficient MCMC sampler written in C++ that interfaces with these models and makes it possible to conduct inference under them. However, it turns out that we can reproduce this core functionality of the program in the model specification language itself2 \u0026ndash; i.e., at the Rev level. The tutorial achieves this by exploiting a feature that is present in the language, but hasn\u0026rsquo;t seen much use in real-world RevBayes analyses: user-defined functions. What\u0026rsquo;s cool / dangerous (delete as appropriate) about teaching material that is closely related to your research interests, and teaching it to grad students who may go on to use it in their own work, is that you get to impress your own pet peeves on them. An example here is my emphasis (see p. 17) on the fact that when we present a single tree from a Bayesian phylogenetic analysis, this tree is just a summary of the result, and not the result itself. The actual result is the entire posterior sample. Too often, paleontologists will speak of, say, the MCC tree as \u0026ldquo;the Bayesian tree\u0026rdquo;, seemingly unaware that it is just one tree among many which were sampled by their analysis. In particularly egregious cases, they might even comment on the resolution of \u0026ldquo;the Bayesian tree\u0026rdquo; and compare it to that of \u0026ldquo;the parsimony tree\u0026rdquo;. This makes no sense, since we can make our summary as resolved or unresolved as we like, and apparent differences in resolution between methods stem simply from the fact that their results are traditionally summarized using different conventions (e.g., the strict consensus of all MPTs in parsimony vs. picking one particular tree in Bayesian inference). When I said an active developer community was a huge benefit when it came to teaching, the converse is also true: using RevBayes in workshop or classroom settings benefits its continued development, since it helps uncover bugs that might otherwise go undetected. Case in point: Exercise 6 in the handout above. In RevBayes, elements of the branch length vector have to be of type RealPos, but when we draw from dnUniform, the resulting stochastic variable is inferred to be of the most restrictive type possible based on the bounds of the distribution. Therefore, drawing from dnUniform(0, 0.5) does not produce a RealPos but rather a Probability, which is a subtype of RealPos with the domain restricted to $[0, 1]$. I reported this as issue #308 specifically because the students ran into it when trying to complete the exercise, and I regret to say that two years later, it is still unresolved.3 If I were to rewrite the handout, I\u0026rsquo;d just have the students experiment with a completely different prior \u0026ndash; e.g., dnExponential(5). Exercise 7, in which the students were supposed to unlink branch lengths across partitions, was a well-intentioned test of their ability to piece together various things they\u0026rsquo;d already learned about Rev, but proved to be far too difficult in practice. If I remember correctly, not a single student figured it out. One figure that I regret not recreating for my handout is this beautiful illustration of the RevBayes move schedule, taken from an unpublished tutorial developed by Mike May and Jiansi Gao:  The final lab of the course was dedicated to tip-dating under the fossilized birth-death (FBD) process, and I tried to build as much as possible on the previous two labs when writing the corresponding handout. I mostly did this by exploiting what Warnock \u0026amp; Wright (2020) called the tripartite model, in which the inference of time-calibrated phylogenies can be decomposed into three mutually independent submodels: the substitution model, which describes how characters change along the branches of the tree; the clock model, which describes how the rate of the substitution process varies across these branches; and the tree model, which jointly specifies the topology of the tree and its branch lengths. As stated in the handout, the switch from time-free inference to tip-dating involves replacing the tree model and adding the clock model, which made it possible to re-use a good amount of the code that I\u0026rsquo;d gone over the week before:\n       Previous Next \u0026nbsp; \u0026nbsp;   /   [pdf]   View the PDF file here.  (function(){ var url = 'Lab8.pdf'; var hidePaginator = \"\" === \"true\"; var hideLoader = \"\" === \"true\"; var selectedPageNum = parseInt(\"\") || 1; var pdfjsLib = window['pdfjs-dist/build/pdf']; if (pdfjsLib.GlobalWorkerOptions.workerSrc == '') pdfjsLib.GlobalWorkerOptions.workerSrc = \"\\/\" + 'js/pdf-js/build/pdf.worker.js'; var pdfDoc = null, pageNum = selectedPageNum, pageRendering = false, pageNumPending = null, scale = 3, canvas = document.getElementById('pdf-canvas-1b53623d'), ctx = canvas.getContext('2d'), paginator = document.getElementById(\"pdf-paginator-1b53623d\"), loadingWrapper = document.getElementById('pdf-loadingWrapper-1b53623d'); showPaginator(); showLoader(); function renderPage(num) { pageRendering = true; pdfDoc.getPage(num).then(function(page) { var viewport = page.getViewport({scale: scale}); canvas.height = viewport.height; canvas.width = viewport.width; var renderContext = { canvasContext: ctx, viewport: viewport }; var renderTask = page.render(renderContext); renderTask.promise.then(function() { pageRendering = false; showContent(); if (pageNumPending !== null) { renderPage(pageNumPending); pageNumPending = null; } }); }); document.getElementById('pdf-pagenum-1b53623d').textContent = num; } function showContent() { loadingWrapper.style.display = 'none'; canvas.style.display = 'block'; } function showLoader() { if(hideLoader) return loadingWrapper.style.display = 'flex'; canvas.style.display = 'none'; } function showPaginator() { if(hidePaginator) return paginator.style.display = 'block'; } function queueRenderPage(num) { if (pageRendering) { pageNumPending = num; } else { renderPage(num); } } function onPrevPage() { if (pageNum = pdfDoc.numPages) { return; } pageNum++; queueRenderPage(pageNum); } document.getElementById('pdf-next-1b53623d').addEventListener('click', onNextPage); pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) { pdfDoc = pdfDoc_; var numPages = pdfDoc.numPages; document.getElementById('pdf-pagecount-1b53623d').textContent = numPages; if(pageNum  numPages) { pageNum = numPages } renderPage(pageNum); }); })();  Notes:\n On p. 7, I say that a good way to explore the parameter space of complex models is to specify the same type of move with different step sizes: e.g., mvSlide with delta=0.01, delta=0.1, and delta=1. That\u0026rsquo;s definitely one way to do it, but if I were to write the handout again, I would instead recommend using the slice move (mvSlice), which automatically chooses its step sizes based on the shape of the likelihood function, so it can propose small steps in some regions of parameter space and large steps in others. As a result, the acceptance rate of the slice move is close to 1, which makes for very efficient exploration. The code from the handout will run with the most recent version of RevBayes (at the time of writing this post, v1.2.5-preview, commit 85cbe87), but it will keep triggering the warning added in PR #559. This is because the analysis will often sample trees with a sampled ancestor at the root (i.e., trees in which a single taxon is ancestral to all others), and the mvRootTimeSlideUniform move, which operates on the age of the root, will attempt to shift its age outside the bounds specified in the taxon file (see the discussion under issue #544). The simplest way to avoid this warning being printed to the screen several hundred thousand times is just to delete or comment out the offending move. The code given in the handout implicitly fixes the age of each tip to the minimum specified in the taxon file. Obviously, in a real-world analysis, we\u0026rsquo;d like to sample the tip ages from their respective uncertainty ranges (Barido-Sottani et al. 2019), or even use the FBD-range model (Stadler et al. 2018) to account for the fact that taxa like \u0026ldquo;Hesperocyoninae\u0026rdquo; include multiple fossil occurrences of different ages. Unfortunately, the latter option is unworkable, because the current implementation of the FBD-range model in RevBayes yields the wrong likelihoods, and I decided not to opt for the former option mostly out of pedagogical laziness. The Rev code for sampling tip ages is quite opaque, and explaining the meaning of the auxiliary variable F or of clamping it to 0 is not an easy task. See the official FBD tutorial for our current best shot at it. If the students try to plug their own numbers into the line of code that calculates the rate of the exponential prior on the age of origin, they might once again run afoul of the RevBayes type system. Let\u0026rsquo;s say we want to change the hard minimum and soft maximum from $38$ and $49$ to $318.1$ and $358.9$, respectively. Both of these values are of type RealPos, but RevBayes quite reasonably cannot guarantee that the result of subtracting one nonnegative real number from another will also be nonnegative. Therefore, the type of $358.9 - 318.1$ is Real, and the whole expression (358.9 - 318.1)/qexp(0.95) evaluates to a Real as well. But unfortunately, that means the reciprocal of the resulting value can no longer be used as the rate parameter of an exponential distribution, which has to be of type RealPos. We can circumvent this problem by writing abs(358.9 - 318.1)/qexp(0.95), abusing the absolute value function as a type cast from Real to RealPos. Another pet peeve I got to point out: in FBD analyses, outgroups are not only unnecessary but potentially detrimental. This is often underappreciated, because most paleontologists perceive Bayesian tip-dating just as an alternative method to be applied to their existing datasets, which were almost always compiled for use with parsimony \u0026ndash; a point that was recently made in another context by Wright \u0026amp; Wynd (2024). Parsimony infers unrooted trees, and outgroups are needed to determine the position of the root after the fact. FBD analyses, on the other hand, infer rooted trees directly, without the need to resort to such a crutch. However, undersampled outgroups \u0026ndash; and outgroups are pretty much always undersampled relative to the ingroup \u0026ndash; violate key assumptions of the FBD model. I haven\u0026rsquo;t seen this pointed out much in the literature; one recent exception would be Gavryushkina \u0026amp; Zhang (2021).  Overall, I had a good time teaching RevBayes, and I\u0026rsquo;m happy to say that two years later, I still stand by my assessment that it was the right choice for this type of course. That doesn\u0026rsquo;t mean I think it would be the best choice for every course. Earlier this year, Diego Pol, with whom I had the pleasure to collaborate on the description of Koleken, asked me what software I\u0026rsquo;d recommend for Bayesian tip-dating if the goal was to design a lab for undergrads that was as simple and user-friendly as possible. Given those criteria, I had to recommend MrBayes over RevBayes. However, when there is enough time to spend on MCMC theory, probabilistic graphical models, and the Rev syntax, using RevBayes in a classroom setting can be a rewarding experience.\nPartitioning by state number: a rant My single biggest worry was that the students would come to dislike RevBayes for being too complicated and wonky. Surprisingly, that proved not to be the case, and I was repeatedly told that the RevBayes-based Bayesian labs were smooth sailing compared to the maximum-likelihood lab we\u0026rsquo;d done one week earlier. Was this because learning how to interpret probabilistic graphical models and code them up in a custom domain-specific programming language is actually pretty easy? Not necessarily, I\u0026rsquo;m afraid. It\u0026rsquo;s just that the maximum-likelihood lab turned out to be particularly frustrating for a reason that ultimately had to do with the highly technical problem of partitioning morphological datasets by the observed number of character states.\nThe notion that partitioning by state number is important in model-based analyses of discrete morphological data is, as far as I can tell, one of those ideas that just sort of float around in the community before someone finally takes it upon themselves to formally demonstrate it in print in a rigorous manner. Brief discussions of it could be found in the literature for some time. Gavryushkina et al. (2017) found that partitioning by state number improved model fit in terms of marginal likelihoods relative to an alternative treatment (default for most software; see below) where a single substitution model is applied to all characters, and the size of its instantaneous rate matrix $Q$ is determined by the maximum of the state numbers observed in the dataset. King et al. (2017) agreed that partitioning by the number of states was desirable but argued that the lower stationary frequencies for characters with higher state numbers need to be countered by increasing exchangeabilities in order to prevent changes in such characters from being artificially upweighted \u0026ndash; an argument I\u0026rsquo;m not sure I buy.4 More recently, Ruebenstahl et al. (2024) discussed the issue in the supplement of their paper on the evolution of sea scorpions. However, it was Khakurel et al. (2024) who finally tackled the issue head-on, and performed a detailed simulation study showing that the use of a single $Q$-matrix which is too large for most characters in the matrix leads to systematic underestimation of branch lengths.\nIf we\u0026rsquo;ve established that partitioning by the number of states matters, how hard is it to implement this option in existing phylogenetic software? It turns out the answer ranges from \u0026ldquo;easy\u0026rdquo; to \u0026ldquo;impossible\u0026rdquo;:\n RAxML: A single $Q$-matrix is applied to the whole dataset, and its size is automatically determined based on the highest-numbered state therein. Manual partitioning might be an option, but since RAxML makes it impossible to treat some multistate characters as ordered and others as unordered, it\u0026rsquo;s just poorly suited to analyses of real-world morphological datasets in general.\n RAxML-NG: The default behavior is the same, but flexibility has increased. The partition file can now directly specify substitution models (not just data types), and instead of a single MULTI data type, we get fine-grained control over the number of states $k$. In theory, this makes it possible to create partition files like this:\nBIN+G+ASC_LEWIS, binary = 1-322 MULTI3_MK+G+ASC_LEWIS, threestate = 323-357 MULTI4_MK+G+ASC_LEWIS, fourstate = 358-377 MULTI5_MK+ASC_LEWIS, fivestate = 378-381  Unfortunately, real-world morphological datasets are never organized by the number of observed states, which means that we\u0026rsquo;re more likely to end up with this abomination:\nBIN+G+ASC_LEWIS, binary = 1, 3-11, 13-22, 24-30, 32-34, 37, 38, 40-45, 47-51, 53-57, 59-62, 64, 65, 67-75, 77-87, 89-91, 93-112, 114-122, 126-131, 133, 135-141, 143-149, 152-162, 164, 165, 167-192, 194, 195, 197-200, 202, 206-214, 216-221, 223-225, 228-237, 239-242, 244-246, 248-252, 254-267, 269-273, 275, 276, 278-291, 293-295, 297-301, 303-305, 307-310, 312-319, 321-327, 329-330, 332-342, 345-346, 348-352, 354, 356-360, 362-365, 367-374, 376-381 MULTI3_MK+G+ASC_LEWIS, threestate = 2, 12, 35, 36, 39, 46, 52, 58, 63, 76, 88, 92, 113, 125, 151, 163, 166, 201, 203-205, 222, 226, 243, 247, 253, 277, 302, 306, 331, 343, 344, 353, 366, 375 MULTI4_MK+G+ASC_LEWIS, fourstate = 23, 31, 123, 124, 132, 134, 150, 193, 196, 215, 227, 238, 268, 274, 292, 296, 311, 320, 328, 347, 355 MULTI5_MK+ASC_LEWIS, fivestate = 66, 142, 227, 361  which, to add insult to injury, is non-trivial to produce, since we first need to write some sort of state-counting script.\n MrBayes: The dataset is automatically partitioned by the number of observed states, so that each partition receives a $Q$-matrix of appropriate size, and the resulting partitions are implicit. This is extremely convenient for the user, but also rather limiting: it is impossible to unlink rate variation or clock models across such partitions, or to assign them different ascertainment bias corrections. The only way around this limitation is to once again specify the partitions manually.\n RevBayes: Partitioning by state number is not automatic, but easy to implement, and we don\u0026rsquo;t have to know the indices of individual characters with a given number of states in advance. The only thing we need is the maximum number of states observed in the dataset (denoted max_state_num in the code below), which we can usually extract from the Nexus file anyway:\nidx = 1 max_state_num = 5 # Start iterating from 2 since we assume there are no 1-state (constant) characters for (i in 2:max_state_num) { # Make a copy of the full character matrix ('morpho') chars[i - 1] \u0026lt;- morpho # Only keep those characters whose state space size equals i chars[i - 1].setNumStatesPartition(i) # Get the number of characters with i states nc = chars[i - 1].nchar() # If this number is greater than zero, create the appropriate Q-matrix if (nc \u0026gt; 0) { print(\u0026quot;There are \u0026quot;+nc+\u0026quot; characters with \u0026quot;+i+\u0026quot; states.\u0026quot;) Qmat[idx] \u0026lt;- fnJC(i) # Draw from the phylogenetic continuous-time Markov chain ctmc[idx] ~ dnPhyloCTMC(tree=tree, Q=Qmat[idx], branchRates=branch_rates, siteRates=char_rates, type=\u0026quot;Standard\u0026quot;, coding=\u0026quot;variable\u0026quot;) # Clamp to the data ctmc[idx].clamp( chars[i - 1] ) # Increment counter idx = idx + 1 } }  Note that the resulting partitions are explicit \u0026ndash; if we wanted to, we could use the idx index to give them unlinked rate variation or clock models, or different ascertainment bias corrections.\n BEAST 2: The dataset is automatically partitioned by the number of observed states, so that each partition receives a $Q$-matrix of appropriate size, and the resulting partitions are explicit, meaning that we can assign them different models if we so choose. Credit where credit is due \u0026ndash; this is the best behavior out of all phylogenetic programs I\u0026rsquo;ve used, hands down.\n  But wait! I still haven\u0026rsquo;t mentioned IQ-TREE, the software I decided to use for the maximum-likelihood lab. Well, IQ-TREE is worse in this regard than RAxML-NG, which is already less than ideal. The basic idea is the same, but subject to the further constraint that we can\u0026rsquo;t even mix binary and multistate characters in the same file. Therefore, if we try to translate our RAxML-NG partition file into a format recognizable by IQ-TREE:\n#nexus begin sets; charset binary = 1 3-11 13-22 24-30 32-34 37 38 40-45 47-51 53-57 59-62 64 65 67-75 77-87 89-91 93-112 114-122 126-131 133 135-141 143-149 152-162 164 165 167-192 194 195 197-200 202 206-214 216-221 223-225 228-237 239-242 244-246 248-252 254-267 269-273 275 276 278-291 293-295 297-301 303-305 307-310 312-319 321-327 329-330 332-342 345-346 348-352 354 356-360 362-365 367-374 376-381; charset threestate = 2 12 35 36 39 46 52 58 63 76 88 92 113 125 151 163 166 201 203-205 222 226 243 247 253 277 302 306 331 343 344 353 366 375; charset fourstate = 23 31 123 124 132 134 150 193 196 215 227 238 268 274 292 296 311 320 328 347 355; charset fivestate = 66 142 227 361; charpartition mine = JC2+ASC+G: binary, MK+ASC+G: threestate, MK+ASC+G: fourstate, MK+ASC: fivestate; end;  we get the following error:\nAlignment most likely contains binary sequences ERROR: Sequence \u0026lt;taxon0\u0026gt; has invalid character 2 at site 2 ERROR: Sequence \u0026lt;taxon1\u0026gt; has invalid character 2 at site 2 ERROR: Sequence \u0026lt;taxon2\u0026gt; has invalid character 2 at site 2 \u0026lt;...\u0026gt; ERROR: ...many more...  The only thing that can save us here is the fact that IQ-TREE also allows individual partitions to come from separate files. This means we have to break up our character matrix into multiple files, each of which contains only those characters that share the same number of observed states:\n#nexus begin sets; charset binary = MK2.phy; charset threestate = MK3.phy; charset fourstate = MK4.phy; charset fivestate = MK5.phy; charpartition mine = JC2+ASC+G: binary, MK+ASC+G: threestate, MK+ASC+G: fourstate, MK+ASC: fivestate, end;  And again, this is all ignoring the fact that in practice, we will likely be dealing with a mix of ordered and unordered characters. So we have to split the dataset by character type first, and by state number second, to end up with something like this:\n#nexus begin sets; charset part1 = MK2.phy; charset part2 = MK3.phy; charset part3 = MK4.phy; charset part4 = MK5.phy; charset part5 = ORDERED3.phy; charset part6 = ORDERED4.phy; charpartition mine = JC2+ASC+G: part1, MK+ASC+G: part2, MK+ASC+G: part3, MK+ASC: part4, ORDERED+ASC+G: part5, ORDERED+ASC: part6; end;  My bright idea for how to keep the IQ-TREE exercise both manageable and theoretically rigorous was to provide the students with an R script that would take as its input a character matrix in Nexus format and a vector of indices of the characters to be ordered, and return partition-specific Phylip data files plus a Nexus partition file (similar to the one shown above) as its output. This way, the ugly preprocessing step would be taken care of, and the students could just focus on experimenting with different settings when executing the program from the command line.\nThe initial version of my script failed for pretty much everyone, and in a unique way in each and every case. I spent a whole week answering emails from students who were understandably anxious that the very first step of their analysis, and the prerequisite for everything else they were supposed to do in their assignment, was failing with error messages they had trouble deciphering. In a few cases, this turned out to be due to genuine mistakes in their Nexus files \u0026ndash; e.g., using illegal symbols in taxon names, or specifying the wrong NCHAR value. More often, however, it turned out that my script made way stronger assumptions about what a matrix file should look like than the actual requirements specified by the Nexus standard, and couldn\u0026rsquo;t deal with perfectly normal variation in things like leading tabs, blank lines after commands, or the delimiter used to separate the taxon names from their corresponding character state strings. Some of the problems I should have definitely foreseen (e.g., what if there are no ordered characters?), but others really were unexpected (one student had a matrix consisting of only ordered characters). All in all, this definitely made me appreciate the Nexus parsers integrated in software like RevBayes and IQ-TREE, which effortlessly handle everything you throw at them. You can see the final outcome of my efforts to robustify the partitioning script here, but needless to say, it is still pretty fragile: it relies on features that the Nexus standard explicitly says are optional, like the NTAX command, and makes all sorts of implicit assumptions about the MATRIX block.\nSoftware discussed in this post  RevBayes: Höhna et al. (2016). https://github.com/revbayes/revbayes. GNU GPL-3.0. RAxML-NG: Kozlov et al. (2019). https://github.com/amkozlov/raxml-ng. GNU AGPL-3.0. RAxML: Stamatakis et al. (2004); Stamatakis (2014). https://github.com/stamatak/standard-RAxML. GNU GPL-3.0. PAUP*: Swofford (2002). https://paup.phylosolutions.com. Copyright © David L. Swofford and Charles D. Bell.5 MrBayes: Huelsenbeck \u0026amp; Ronquist (2001); Ronquist et al. (2012). https://github.com/NBISweden/MrBayes. GNU GPL-3.0. IQ-TREE: Nguyen et al. (2015); Minh et al. (2020). https://github.com/iqtree/iqtree2. GNU GPL-2.0. BEAST 2: Bouckaert et al. (2014, 2019). https://github.com/CompEvol/beast2. GNU LGPL-2.1.  References  Barido-Sottani J, Aguirre-Fernández G, Hopkins MJ, Stadler T, Warnock RCM. 2019. Ignoring stratigraphic age uncertainty leads to erroneous estimates of species divergence times under the fossilized birth–death process. Proc. R. Soc. B 286(1902): 20190685 Bleidorn C. 2017. Phylogenomics: An Introduction. Cham, Switzerland: Springer Bouckaert RR, Heled J, Kühnert D, Vaughan TG, Wu C-H, Xie D, Suchard MA, Rambaut A, Drummond AJ. 2014. BEAST 2: A software platform for Bayesian evolutionary analysis. PLoS Comp. Biol. 10(4): e1003537 Bouckaert RR, Vaughan TG, Barido-Sottani J, Duchêne S, Fourment M, Gavryushkina A, Heled J, Jones G, Kühnert D, De Maio N, Matschiner M, Mendes FK, Müller NF, Ogilvie HA, du Plessis L, Popinga A, Rambaut A, Rasmussen D, Siveroni I, Suchard MA, Wu C-H, Xie D, Zhang C, Stadler T, Drummond AJ. 2019. BEAST 2.5: An advanced software platform for Bayesian evolutionary analysis. PLoS Comp. Biol. 15(4): e1006650 Černý D, Simonoff AL. 2023. Statistical evaluation of character support reveals the instability of higher-level dinosaur phylogeny. Sci. Reports 13(1): 9273 Drummond AJ, Chen K, Mendes FK, Xie D. 2023. LinguaPhylo: A probabilistic model specification language for reproducible phylogenetic analyses. PLoS Comp. Biol. 19(7): e1011226 Felsenstein J. 2004. Inferring Phylogenies. Sunderland, MA: Sinauer Associates Gavryushkina A, Heath TA, Ksepka DT, Stadler T, Welch D, Drummond AJ. 2017. Bayesian total-evidence dating reveals the recent crown radiation of penguins. Syst. Biol. 66(1): 57\u0026ndash;73 Gavryushkina A, Zhang C. 2021. Total-evidence dating and the fossilized birth–death model. 175\u0026ndash;193 in: Ho SYW, ed. The Molecular Evolutionary Clock: Theory and Practice. Cham, Switzerland: Springer Höhna S, Landis MJ, Heath TA, Boussau B, Lartillot N, Moore BR, Huelsenbeck JP, Ronquist F. 2016. RevBayes: Bayesian phylogenetic inference using graphical models and an interactive model-specification language. Syst. Biol. 65(4): 726\u0026ndash;736 Huelsenbeck JP, Ronquist F. 2001. MRBAYES: Bayesian inference of phylogenetic trees. Bioinform. 17(8): 754\u0026ndash;755 Khakurel B, Grigsby C, Tran TD, Zariwala J, Höhna S, Wright AM. 2024. The fundamental role of character coding in Bayesian morphological phylogenetics. Syst. Biol. doi:10.1093/sysbio/syae033 King B, Qiao T, Lee MSY, Zhu M, Long JA. 2017. Bayesian morphological clock methods resurrect placoderm monophyly and reveal rapid early evolution in jawed vertebrates. Syst. Biol. 66(4): 499\u0026ndash;516 Kozlov AM, Darriba D, Flouri T, Morel B, Stamatakis A. 2019. RAxML-NG: a fast, scalable and user-friendly tool for maximum likelihood phylogenetic inference. Bioinform. 35(21): 4453\u0026ndash;4455 Minh BQ, Schmidt HA, Chernomor O, Schrempf D, Woodhams MD, von Haeseler A, Lanfear R. 2020. IQ-TREE 2: New models and efficient methods for phylogenetic inference in the genomic era. Mol. Biol. Evol. 37(5): 1530\u0026ndash;1534. Corrigendum: 37(8): 2461 Nazari V, Pasqualone A, Pieroni A, Todisco V, Belardinelli S, Pievani T. 2024. Evolution of the Italian pasta ripiena: the first steps toward a scientific classification. Discov. Food 4: 57 Nguyen L-T, Schmidt HA, von Haeseler A, Minh BQ. 2015. IQ-TREE: A fast and effective stochastic algorithm for estimating maximum-likelihood phylogenies. Mol. Biol. Evol. 32(1): 268\u0026ndash;274 Ronquist F, Teslenko M, van der Mark P, Ayres DL, Darling A, Höhna S, Larget B, Liu L, Suchard MA, Huelsenbeck JP. 2012. MrBayes 3.2: Efficient Bayesian phylogenetic inference and model choice across a large model space. Syst. Biol. 61(3): 539\u0026ndash;542 Ruebenstahl A, Mongiardino Koch N, Lamsdell JC, Briggs DEG. 2024. Convergent evolution of giant size in eurypterids. Proc. R. Soc. B 291(2027): 20241184 Stadler T, Gavryushkina A, Warnock RCM, Drummond AJ, Heath TA. 2018. The fossilized birth-death model for the analysis of stratigraphic range data under different speciation modes. J. Theor. Biol. 447: 41\u0026ndash;55 Stamatakis A. 2014. RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies. Bioinform. 30(9): 1312\u0026ndash;1313 Stamatakis A, Ludwig T, Meier H. 2004. A fast program for maximum likelihood-based inference of large phylogenetic trees. 197\u0026ndash;201 in: SAC \u0026lsquo;04: Proceedings of the 2004 ACM Symposium on Applied Computing. New York, NY: Association for Computing Machinery Swofford DL. 2002. PAUP*: Phylogenetic Analysis Using Parsimony (*and Other Methods). Version 4. Sunderland, MA: Sinauer Associates Tedford RH, Wang X-M, Taylor BE. 2009. Phylogenetic systematics of the North American fossil Caninae (Carnivora: Canidae). Bull. Am. Mus. Nat. Hist. 325: 1\u0026ndash;218 Warnock RCM, Wright AM. 2020. Understanding the tripartite approach to Bayesian divergence time estimation. In: Sumrall CD, ed. Elements of Paleontology. Cambridge, UK: Cambridge University Press Wright AM, Wynd BM. 2024. Modeling of rate heterogeneity in datasets compiled for use with parsimony. bioRxiv doi:10.1101\\/2024.06.26.600858v1 Yang Z. 2014. Molecular Evolution: A Statistical Approach. Oxford, UK: Oxford University Press   This is, in fact, an important \u0026ndash; and I think underappreciated \u0026ndash; cultural distinction between morphological and molecular phylogenetics. For people with a molecular background, phylogenetics mostly begins once the dataset has been assembled, and the question arises of what to do with it. Textbooks like Felsenstein (2004) or Yang (2014) don\u0026rsquo;t start with instructions on how to operate an Illumina sequencer, and it would be strange if they did (though see Bleidorn 2017). It is only with the problem of co-inferring alignment and phylogeny \u0026ndash; a practice long recognized as desirable but often computationally prohibitive \u0026ndash; that the dataset is not treated as a given. On the other hand, paleontologists sometimes seem to believe almost the exact opposite: that phylogenetics ends with the assembly of the character matrix, and once that crucial step has been accomplished, it matters little what methods one uses to analyze it. This belief (which Graham\u0026rsquo;s course did its best to combat) is usually justified by the argument that if the matrix is \u0026ldquo;flawed\u0026rdquo; or \u0026ldquo;miscoded\u0026rdquo;, no method will be able to extract useful phylogenetic information from it \u0026ndash; often summed up by the catchphrase \u0026ldquo;garbage in, garbage out\u0026rdquo;. Exactly what that implies about the readiness of paleontologists to believe that their colleagues are in the habit of producing garbage is left as an exercise to the reader. ^ With a big hit to performance, of course, due to the overhead introduced by the interpreter. ^ In part, this probably reflects the fact that the issue is just a particular instance of a more general problem, namely the fact that Rev is strongly but implicitly typed. The choice is certainly justifiable, as it makes it easy for Rev to interface with the C++ back end, while keeping the front end simple for biologists who are most likely to be familiar with dynamically typed languages like R and Python. However, in cases like this, it can feel like the worst of both worlds. Even though every probability is also a nonnegative real (\u0026rdquo;RealPos\u0026rdquo; in Rev parlance), Dist_unifProbability does not derive from Distribution__RealPos, so you can\u0026rsquo;t plug it into dnUniformTopologyBranchLength which expects the latter \u0026ndash; something that wouldn\u0026rsquo;t happen in a weakly typed language. You\u0026rsquo;d be forgiven for thinking that the next best thing would be to explicitly cast 0.5 as a RealPos rather than a Probability, but alas, you don\u0026rsquo;t get explicit casts with implicit typing. (In reality, it\u0026rsquo;s even worse: Rev actually does have a function-style cast for converting from RealPos to Probability, but not one to go from Probability to RealPos.) ^ I\u0026rsquo;ve taken the liberty of discussing it with the authors of Khakurel et al. (2024), and I don\u0026rsquo;t think the proposed solution would work even if the problem were real, which is also somewhat questionable. ^ Dave Swofford has been promising to make PAUP* open-source for many years now. Here\u0026rsquo;s hoping it actually happens someday. ^   ","date":1730075400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730075400,"objectID":"754712ffcd46543db81b29243e0970a0","permalink":"/post/teaching_revbayes/","publishdate":"2024-10-28T00:30:00Z","relpermalink":"/post/teaching_revbayes/","section":"post","summary":"Introduction In the fall of 2022, I got to TA a course called Phylogenetics and the Fossil Record, taught by my PhD advisor, Graham Slater. Although I TA\u0026rsquo;ed almost every single quarter during my time at the University of Chicago, this particular experience was pretty unique, for a number of reasons. First, it was a mixed undergraduate/graduate course, whereas all the other courses I TA\u0026rsquo;ed were offered exclusively to undergrads, and often specifically to non-science majors.","tags":[],"title":"Teaching RevBayes: reflections and materials","type":"post"},{"authors":["Diego Pol","Mattia Antonio Baiano","David Černý","Fernando E. Novas","Ignacio A. Cerda","Michael Pittman"],"categories":null,"content":"","date":1716249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716249600,"objectID":"41620992347d449a0712d55da3d450e8","permalink":"/publication/pol_et_al_2024/","publishdate":"2024-05-20T20:00:00Z","relpermalink":"/publication/pol_et_al_2024/","section":"publication","summary":"Gondwanan dinosaur faunae during the 20 Myr preceding the Cretaceous--Palaeogene (K/Pg) extinction included several line- ages that were absent or poorly represented in Laurasian landmasses. Among these, the South American fossil record contains diverse abelisaurids, arguably the most successful groups of carnivorous dinosaurs from Gondwana in the Cretaceous, reaching their highest diversity towards the end of this period. Here we describe _Koleken inakayali_ gen. et sp. n., a new abelisaurid from the La Colonia Formation (Maastrichtian, Upper Cretaceous) of Patagonia. _Koleken inakayali_ is known from several skull bones, an almost complete dorsal series, complete sacrum, several caudal vertebrae, pelvic girdle and almost complete hind limbs. The new abelisaurid shows a unique set of features in the skull and several anatomical differences from _Carnotaurus sastrei_ (the only other abelisaurid known from the La Colonia Formation). _Koleken inakayali_ is retrieved as a brachyrostran abelisaurid, clustered with other South American abelisaurids from the latest Cretaceous (Campanian--Maastrichtian), such as _Aucasaurus_, _Niebla_ and _Carnotaurus_. Leveraging our phylogeny estimates, we explore rates of morphological evolution across ceratosaurian lineages, finding them to be particularly high for elaphrosaurine noasaurids and around the base of Abelisauridae, before the Early Cretaceous radiation of the latter clade. The Noasauridae and their sister clade show contrasting patterns of morphological evolution, with noasaurids undergoing an early phase of accelerated evolution of the axial and hind limb skeleton in the Jurassic, and the abelisaurids exhibiting sustained high rates of cranial evolution during the Early Cretaceous. These results provide much needed context for the evolutionary dynamics of ceratosaurian theropods, contributing to broader understanding of macroevolutionary patterns across dinosaurs.\n","tags":["Koleken","Abelisaurid","Ceratosauria","Theropods","Dinosaurs","Evolutionary rates"],"title":"A new abelisaurid dinosaur from the end Cretaceous of Patagonia and evolutionary rates among the Ceratosauria","type":"publication"},{"authors":["David Černý","Ashley L. Simonoff"],"categories":null,"content":"","date":1686096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686096000,"objectID":"9973bd0d670fbcac92672574e8bea811","permalink":"/publication/cerny_et_simonoff_2023/","publishdate":"2023-06-10T08:00:00Z","relpermalink":"/publication/cerny_et_simonoff_2023/","section":"publication","summary":"The interrelationships of the three major dinosaur clades (Theropoda, Sauropodomorpha, and Ornithischia) have come under increased scrutiny following the recovery of conflicting phylogenies by a large new character matrix and its extensively modified revision. Here, we use tools derived from recent phylogenomic studies to investigate the strength and causes of this conflict. Using maximum likelihood as an overarching framework, we examine the global support for alternative hypotheses as well as the distribution of phylogenetic signal among individual characters in both the original and rescored dataset. We find the three possible ways of resolving the relationships among the main dinosaur lineages (Saurischia, Ornithischiformes, and Ornithoscelida) to be statistically indistinguishable and supported by nearly equal numbers of characters in both matrices. While the changes made to the revised matrix increased the mean phylogenetic signal of individual characters, this amplified rather than reduced their conflict, resulting in greater sensitivity to character removal or coding changes and little overall improvement in the ability to discriminate between alternative topologies. We conclude that early dinosaur relationships are unlikely to be resolved without fundamental changes to both the quality of available datasets and the techniques used to analyze them.\n","tags":null,"title":"Statistical evaluation of character support reveals the instability of higher-level dinosaur phylogeny","type":"publication"},{"authors":["David Černý","Paul van Els","Rossy Natale","Steven M. S. Gregory"],"categories":null,"content":"","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683849600,"objectID":"0738aaed0f3b6f57eb0192942fe54372","permalink":"/publication/cerny_et_al_2023/","publishdate":"2019-06-12T20:00:00Z","relpermalink":"/publication/cerny_et_al_2023/","section":"publication","summary":"Recent phylogenetic findings indicate that the divergence of the Neotropical taxa _Burhinus bistriatus_ (Wagler, 1829) and _Burhinus superciliaris_ (Tschudi, 1843) from other thick- knees (Burhinidae) predates the split between the remaining species of _Burhinus_ and the genus _Esacus_, rendering the genus _Burhinus_ paraphyletic. The great age of the former divergence and potential homonymy issues stemming from treating _Esacus_ Lesson, 1831 as a junior subjective synonym of _Burhinus_ Illiger, 1811 suggest that the emergent paraphyly is best prevented by introducing a new genus-group name for the two New World species of _Burhinus_. Accordingly, we describe a new genus, _Hesperoburhinus_ gen. nov., under Article 13.1.1 and Article 16.1 of the International Code of Zoological Nomenclature (ICZN, 1999).\nEstudios filogenéticos recientes indican que la divergencia de los taxones neotropicales _Burhinus bistriatus_ (Wagler, 1829) y _Burhinus superciliaris_ (Tschudi, 1843) de otros alcaravanes (Burhinidae) es más antigua que la diversificación de las especies de los géneros _Burhinus_ y _Esacus_, lo que hace que el género Burhinus sea parafilético. La gran antigüedad de las dos especies neotropicales de Burhinidae y los posibles problemas de homonimia derivados del tratamiento de _Esacus_ Lesson, 1831 como un sinónimo subjetivo menor de _Burhinus_ Illiger, 1811 sugieren que la parafilia emergente se previene mejor introduciendo un nuevo nombre de género para las dos especies del Nuevo Mundo. En consecuencia, se propone un nuevo género, _Hesperoburhinus_ gen. nov., en cumplimiento de los Artículos 13.1.1 y 16.1 del Código Internacional de Nomenclatura Zoológica (ICZN, 1999).\n","tags":["Burhinidae","_Burhinus_","Double-striped thick-knee","_Esacus_","_Hesperoburhinus_ gen. nov.","Neotropics","paraphyly","Peruvian thick-knee","phylogeny","taxonomy","Thick-knees"],"title":"A new genus-group name for Burhinus bistriatus (Wagler, 1829) and Burhinus superciliaris (Tschudi, 1843)","type":"publication"},{"authors":["David Černý","Graham J. Slater"],"categories":null,"content":"","date":1673715600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673715600,"objectID":"6b786e35b86fe2651dc5ed12d78a2560","permalink":"/poster/ssb_2023/","publishdate":"2023-02-01T08:00:00Z","relpermalink":"/poster/ssb_2023/","section":"poster","summary":"In recent years, sparse molecular supermatrices have been used to infer time-scaled \"macrophylogenies\" with thousands or tens of thousands of tips. However, since the joint Bayesian inference of tree topology and divergence times remains unfeasible at such scales, tree size often comes at the cost of methodological sophistication -- a problem that has not been fully resolved by the recently introduced \"backbone-and-patch\" approach. Historically, supertree inference has represented a popular alternative to supermatrix-based approaches, but few supertree methods can simultaneously estimate tree topology and branch lengths, or propagate the uncertainty associated with the source trees through the estimation process. Here, we present a new method, Bayesian Least-Squares Supertrees (BLeSS), that achieves these desirable properties by combining the previously proposed average distance matrix and exponential error approaches into a single probabilistic model. The method takes a profile of ultrametric time trees as its input, and returns a posterior distribution of time-scaled supertrees as its output. BLeSS is implemented in RevBayes, and can be readily combined with other sources of information such as node calibrations, topological constraints, or differential weighting of source trees. Large-scale simulations suggest that the approach performs well across a wide range of tree shapes and missing data distributions. The approach can be extended to trees with non-contemporaneous tips by relaxing the ultrametricity assumption, potentially enabling the inference of fossil phylogenies of previously unparalleled size.\n","tags":[],"title":"Bayesian Least-Squares Supertrees (BLeSS): a flexible method for inferring large time-calibrated phylogenies","type":"poster"},{"authors":["David Černý"],"categories":null,"content":"","date":1665307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665307200,"objectID":"b946437f1fa53cafff34c8ec5ca00101","permalink":"/talk/gsa_2022/","publishdate":"2022-10-20T21:00:00Z","relpermalink":"/talk/gsa_2022/","section":"talk","summary":"Since 2017, multiple studies have cast doubt on the traditional view of large-scale dinosaur phylogeny, according to which the long-necked, herbivorous sauropodomorphs and the ancestrally carnivorous theropods form a monophyletic group (Saurischia) to the exclusion of the “bird-hipped” ornithischians. Emerging alternatives to this traditional arrangement include a sister-group relationship between Ornithischia and Sauropodomorpha (Ornithischiformes); a topology in which the ornithischians are sister to, or even nested within, Theropoda (Ornithoscelida); and the inclusion of the putatively non-dinosaurian Silesauridae within Ornithischia. Some (though not all) of these hypotheses have received support from formal phylogenetic analyses, a fact that has been often attributed to character coding differences among the underlying datasets. However, following a common practice within the parsimony phylogenetic framework, such analyses usually each produced a single point estimate of dinosaurian phylogeny, without determining whether it explained observed character data significantly better than the competing hypotheses. Moreover, despite the fact that improved congruence between phylogeny and stratigraphy has been put forward as a key piece of evidence in favor of some of the recently proposed non-standard hypotheses, none of the analyses performed so far has allowed stratigraphic ages to inform phylogenetic inference. Here, I address both of these shortcomings by taking advantage of the tools recently made available in the RevBayes phylogenetic software package, and conduct extensive Bayes factor model comparisons among 20 alternative phylogenetic topologies in both time-free and tip-dated settings. By repeating the comparisons on three recently published datasets that have produced discordant parsimony point estimates, I also show how this approach can be extended to evaluate the relative contributions of character scoring changes and stratigraphic information to the preference for competing early dinosaur topologies. The results obtained here highlight the importance of explicit hypothesis testing in modern morphological phylogenetics, and of integrating character data and stratigraphic evidence in a single coherent statistical framework.\n","tags":[],"title":"Relative impact of character coding differences and stratigraphic information on the support for alternative early dinosaur phylogenies","type":"talk"},{"authors":["David Černý","Rossy Natale"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"2563efc12fa85dd053cdd2df6ce50894","permalink":"/publication/cerny_et_natale_2022/","publishdate":"2022-10-15T20:30:00Z","relpermalink":"/publication/cerny_et_natale_2022/","section":"publication","summary":"Shorebirds (Charadriiformes) are a globally distributed clade of modern birds and, due to their ecological and morphological disparity, a frequent subject of comparative studies. While molecular phylogenies have been key to establishing the suprafamilial backbone of the charadriiform tree, a number of relationships at both deep and shallow taxonomic levels remain poorly resolved. The timescale of shorebird evolution also remains uncertain as a result of extensive disagreements among the published divergence dating studies, stemming largely from different choices of fossil calibrations. Here, we present the most comprehensive non-supertree phylogeny of shorebirds to date, based on a total-evidence dataset comprising 353 ingroup taxa (90% of all extant or recently extinct species), 27 loci (15 mitochondrial and 12 nuclear), and 69 morphological characters. We further clarify the timeline of charadriiform evolution by time-scaling this phylogeny using a set of 14 up-to-date and thoroughly vetted fossil calibrations. In addition, we assemble a taxonomically restricted 100-locus dataset specifically designed to resolve outstanding problems in higher-level charadriiform phylogeny. In terms of tree topology, our results are largely congruent with previous studies but indicate that some of the conflicts among earlier analyses reflect a genuine signal of pervasive gene tree discordance. Monophyly of the plovers (Charadriidae), the position of the ibisbill (_Ibidorhyncha_), and the relationships among the five subfamilies of the gulls (Laridae) could not be resolved even with greatly increased locus and taxon sampling. Moreover, several localized regions of uncertainty persist in shallower parts of the tree, including the interrelationships of the true auks (Alcinae) and anarhynchine plovers. Our node-dating and macroevolutionary rate analyses find support for a Paleocene origin of crown-group shorebirds, as well as exceptionally rapid recent radiations of Old World oystercatchers (Haematopodidae) and select genera of gulls. Our study underscores the challenges involved in estimating a comprehensively sampled and carefully calibrated time tree for a diverse avian clade, and highlights areas in need of further research.\n","tags":["Phylogeny","Birds","Charadriiformes","Fossil calibrations","Macroevolution"],"title":"Comprehensive taxon sampling and vetted fossils help clarify the time tree of shorebirds (Aves, Charadriiformes)","type":"publication"},{"authors":["David Černý","Rossy Natale"],"categories":null,"content":"","date":1624291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624291200,"objectID":"fabcfec67fa6f857260f2692ecfaeba4","permalink":"/talk/evolution_2021/","publishdate":"2021-08-13T16:00:00Z","relpermalink":"/talk/evolution_2021/","section":"talk","summary":"Shorebirds (Aves: Charadriiformes) represent one of the most species-rich orders of non-passerine birds, and their ecomorphological disparity has inspired a number of comparative studies. However, the lack of a reliably time-calibrated and taxonomically comprehensive phylogeny for the clade as a whole has impeded efforts to extend such studies to the ordinal level. Previous estimates of the age of the charadriiform crown group have ranged from the Early Cretaceous to the late Eocene, in both cases contradicting the known fossil record. Here, we present a total-evidence charadriiform phylogeny containing 336 species (~89% of the extant diversity) based on a 24-locus supermatrix and 69 morphological characters. We estimated divergence times on the fixed total-evidence topology using MCMCTree, a subset of 8 clock-like loci, and 16 extensively vetted fossil calibrations. The autocorrelated and uncorrelated relaxed clock models both place the origin of the charadriiform crown group in the Paleocene (95% HPD: 55.0--63.0 and 59.3--64.8 Ma, respectively), consistent with the known fossil record, but differ with regard to the timing of the seagull radiation (Larinae). This difference propagates into downstream analyses of diversification rates, causing BAMM to infer a speciation rate shift on the uncorrelated-rates tree but not the autocorrelated-rates tree favored by Bayes factor comparisons. Contrary to some previous findings, our results suggest that investigating the sensitivity of macroevolutionary rate estimates to the modeling assumptions made in time tree inference is essential for establishing the tempo and mode of clade evolution.\n","tags":[],"title":"Vetted calibrations and comprehensive taxon sampling clarify the timescale of shorebird evolution","type":"talk"},{"authors":["David Černý","Daniel Madzia","Graham J. Slater"],"categories":null,"content":"","date":1623283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623283200,"objectID":"66f16a4177c11b9ee9e16ec4c240e6e5","permalink":"/publication/cerny_et_al_2021/","publishdate":"2019-06-12T20:00:00Z","relpermalink":"/publication/cerny_et_al_2021/","section":"publication","summary":"Changes in speciation and extinction rates are key to the dynamics of clade diversification, but attempts to infer them from phylogenies of extant species face challenges. Methods capable of synthesizing information from extant and fossil species have yielded novel insights into diversification rate variation through time, but little is known about their behavior when analyzing entirely extinct clades. Here, we use empirical and simulated data to assess how two popular methods, PyRate and Fossil BAMM, perform in this setting. We inferred the first tip-dated trees for ornithischian dinosaurs, and combined them with fossil occurrence data to test whether the clade underwent an end-Cretaceous decline. We then simulated phylogenies and fossil records under empirical constraints to determine whether macroevolutionary and preservation rates can be teased apart under paleobiologically realistic conditions. We obtained discordant inferences about ornithischian macroevolution including a long-term speciation rate decline (BAMM), mostly flat rates with a steep diversification drop (PyRate) or without one (BAMM), and episodes of implausibly accelerated speciation and extinction (PyRate). Simulations revealed little to no conflation between speciation and preservation, but yielded spuriously correlated speciation and extinction estimates while time-smearing tree-wide shifts (BAMM) or overestimating their number (PyRate). Our results indicate that the small phylogenetic datasets available to vertebrate paleontologists and the assumptions made by current model-based methods combine to yield potentially unreliable inferences about the diversification of extinct clades. We provide guidelines for interpreting the results of the existing approaches in light of their limitations, and suggest how the latter may be mitigated.\n","tags":["BAMM","diversification","fossils","macroevolutionary rates","Ornithischia","PyRate"],"title":"Empirical and methodological challenges to the model-based inference of diversification rates in extinct clades","type":"publication"},{"authors":["David Černý"],"categories":["R"],"content":" The summary of the posterior from a Bayesian tip-dating analysis – e.g., the maximum clade credibility tree computed by TreeAnnotator from a BEAST 2 posterior – usually provides a whole wealth of information to the user, and while barebones, quick-and-dirty plotting of the results using FigTree or plot.phylo() is good enough for assessing whether the results are reasonable or not, it definitely doesn’t provide publication-quality figures. Below, I’ll try to show how such figures can be made by combining several existing R packages.\nStarting point: strap The geoscalePhylo() function from the strap package (Bell \u0026amp; Lloyd 2014) is well-known and widely used. It plots a time tree against a nice colorful timescale (the colors are the official color codes of the Commission for the Geological Map of the World), and includes other niceties inherited from plot.phylo(), such as automatically stripping tip names of underscores and printing them in italics. One of the cool options we have at our disposal with geoscalePhylo() is to visualize the uncertainty in the ages of not just the internal nodes (we do that further down below), but also the tips. We can do that using an age range table like the one below:\nNote: As pointed out on Facebook by David Bapst, the ages argument of geoscalePhylo() serves primarily for visualizing taxon durations in the fossil record; i.e., the time intervals between the first and last appearance. If a taxon is only known from a single stratigraphically unique occurrence, its first and last appearance will coincide; however, the age uncertainty associated with that occurrence can still be usefully represented using a range. This is what we’re doing below.\nage_table \u0026lt;- read.table(\u0026quot;~/age_ranges.txt\u0026quot;, stringsAsFactors = F) head(age_table) ## V1 V2 V3 ## 1 Abrictosaurus_consors 190.8 201.3 ## 2 Agilisaurus_louderbacki 163.5 170.3 ## 3 Albalophosaurus_yamaguchiorum 132.9 139.8 ## 4 Aquilops_americanus 99.6 109.0 ## 5 Archaeoceratops_oshimai 113.0 129.4 ## 6 Auroraceratops_rugosus 100.5 129.4 We need to reshuffle our age range table a bit, since geoscalePhylo() needs a matrix whose first and last appearance dates are in the right order, and which has exactly the right column and row names:\nif(!require(\u0026quot;phytools\u0026quot;)) {install.packages(\u0026quot;phytools\u0026quot;)} if(!require(\u0026quot;strap\u0026quot;)) {install.packages(\u0026quot;strap\u0026quot;)} library(phytools) library(strap) my_ages \u0026lt;- cbind(as.numeric(age_table[,3]), as.numeric(age_table[,2])) colnames(my_ages) \u0026lt;- c(\u0026quot;FAD\u0026quot;, \u0026quot;LAD\u0026quot;) rownames(my_ages) \u0026lt;- age_table[,1] tree \u0026lt;- read.nexus(\u0026quot;~/my_MCC_tree.tre\u0026quot;) # geoscalePhylo() needs the $root.time element for plotting tree$root.time \u0026lt;- max(nodeHeights(tree)) + 66.0 geoscalePhylo(ladderize(tree, right = F), ages = my_ages, x.lim = c(0, 240), cex.tip = 0.7, cex.age = 1.3, cex.ts = 1) Internally, geoscalePhylo() calls the plot.phylo() function bundled with ape, and so it accepts all of the latter’s arguments. We can make use of this to highlight clades.\nLet’s assume that we have a list where each clade to be highlighted gets a pair of “anchors”, whose MRCA is also the MRCA of the entire clade – like this one:\nmy_dino_list \u0026lt;- list(c(\u0026quot;Abrictosaurus_consors\u0026quot;, \u0026quot;Tianyulong_confuciusi\u0026quot;), c(\u0026quot;Goyocephale_lattimorei\u0026quot;, \u0026quot;Wannanosaurus_yansiensis_\u0026quot;), c(\u0026quot;Camptosaurus_dispar\u0026quot;, \u0026quot;Dryosaurus_altus_\u0026quot;), c(\u0026quot;Changchunsaurus_parvus\u0026quot;, \u0026quot;Hypsilophodon_foxii_\u0026quot;), c(\u0026quot;Aquilops_americanus\u0026quot;, \u0026quot;Xuanhuaceratops_niei\u0026quot;), c(\u0026quot;Euoplocephalus_tutus\u0026quot;, \u0026quot;Gargoyleosaurus_parkpinorum\u0026quot;), c(\u0026quot;Hesperosaurus_mjosi\u0026quot;, \u0026quot;Isaberrysaura_mollensis\u0026quot;)) What we want to do is (1) find the MRCA of each vector of tip names in the list, (2) assign a certain color to all tips descended from that node, and (3) assign the same color to all branches descended from it. The former is pretty easy:\ntip.coloring \u0026lt;- function(tree, clade_list, group_cols) { cols \u0026lt;- rep(\u0026quot;black\u0026quot;, length(tree$tip.label)) for(i in 1:length(clade_list)) { clade_mrca \u0026lt;- getMRCA(tree, clade_list[[i]]) all_dscndn \u0026lt;- phytools::getDescendants(tree, clade_mrca) tips_only \u0026lt;- all_dscndn[all_dscndn \u0026lt;= Ntip(tree)] cols[tips_only] \u0026lt;- group_cols[i] } return(cols) } Here, we are assuming that the user specifies which color to assign to which clade, rather than creating the colors within the function itself. An additional step is involved when we need to filter the descendant nodes down to tips only: we could get rid of it by using a different function, like Descendants() from phangorn (Schliep 2010), which takes node type as an argument. Here, we exploit the fact that in many of the R packages dealing with phylogenetic trees, the default node labeling scheme assigns numbers from 1 to \\(n\\) to the tips (leaves), \\(n+1\\) to the root, and \\(n+2\\) thru \\(2n-1\\) to the remaining internal nodes. Conversely, we can count on the fact that nodes labeled with numbers less than or equal to \\(n\\) are the tips.\nThe step that consists of coloring all branches descended from the same MRCA is more involved. Fortunately, the indefatigable Liam Revell provides code that does just that in one of the posts on his excellent phytools blog.\nHere, we simply package that code into a function analogous to the one shown above:\nbranch.coloring \u0026lt;- function(tree, clade_list, group_cols) { cols \u0026lt;- rep(\u0026quot;black\u0026quot;, nrow(tree$edge)) for(i in 1:length(clade_list)) { clade_mrca \u0026lt;- getMRCA(tree, clade_list[[i]]) all_dscndn \u0026lt;- phytools::getDescendants(tree, clade_mrca) cols[sapply(all_dscndn, function(x, y) which(y == x), y = tree$edge[,2])] \u0026lt;- group_cols[i] } return(cols) }  Adding HPDs: phyloch and weird loops The next thing we’d like to do than can’t be easily done using any of the many available geoscalePhylo arguments is to add 95% highest posterior density (HPD) intervals to the nodes of our tree.\nThe first step is to extract the necessary information from the annotated Nexus file produced by TreeAnnotator. There used to be several options for parsing such files; my favorite one was probably read.annotated.nexus() from the OutbreakTools library (Jombart et al. 2014), which unfortunately seems to have lately fallen victim to package dependency troubles. Nevertheless, the read.beast() function from the phyloch package (Heibl 2013) provides a great alternative. Note that we might want to define a new “annotation” (more accurately, add a new element to the list by which the tree is internally represented in R) that doesn’t care about how exactly we got our HPDs (from common ancestor heights? from median heights?) and that can be further manipulated:\nif(!require(\u0026quot;phyloch\u0026quot;)) { install.packages(\u0026quot;remotes\u0026quot;) remotes::install_github(\u0026quot;fmichonneau/phyloch\u0026quot;) } library(phyloch) annot_tree \u0026lt;- phyloch::read.beast(\u0026quot;~/my_MCC_tree.tre\u0026quot;) # If the Nexus file has common ancestor node heights in it, extract those; otherwise extract # the mean/median ones. if (is.null(annot_tree$`CAheight_95%_HPD_MIN`)) { annot_tree$min_ages \u0026lt;- annot_tree$`height_95%_HPD_MIN` annot_tree$max_ages \u0026lt;- annot_tree$`height_95%_HPD_MAX` } else { annot_tree$min_ages \u0026lt;- annot_tree$`CAheight_95%_HPD_MIN` annot_tree$max_ages \u0026lt;- annot_tree$`CAheight_95%_HPD_MAX` } We can also add an arbitrary offset to these ages without overriding the original annotations. Recently, a new class called TreeWOffset was introduced into BEAST 2 to store the age of the youngest tip. This comes in handy when our tree is entirely extinct, and we have age ranges associated with all tips including the youngest one(s). This class allows the ages of such tips to still be sampled from their ranges, effectively leading to the estimation of the “offset” of the tree from the present. Perhaps it is this offset that we want to add to the boundaries of our HPDs. Below, we assume that we have already summarized the posterior of all continuous parameters (including the offset) using LogAnalyser or a similar utility, and printed the results to a parsable text file. The TreeAnnotator-produced Nexus file is of no help here.\nparams \u0026lt;- read.table(\u0026quot;~/loganalyser_params.txt\u0026quot;, header = T, stringsAsFactors = F) # Check whether \u0026#39;offset\u0026#39; was actually used and logged: if (length(params$mean[params$statistic == \u0026quot;offset\u0026quot;] != 0)) { offset \u0026lt;- params$mean[params$statistic == \u0026quot;offset\u0026quot;] annot_tree$min_ages \u0026lt;- annot_tree$min_ages + offset annot_tree$max_ages \u0026lt;- annot_tree$max_ages + offset } The most complicated step consists of using this info to actually draw the HPDs – this is often done using half-transparent color bars – around the nodes. The basis for what we are going to do is again provided by Liam Revell.\nHowever, as we see below, our attempt to simply reuse the code given in the blog post does not produce satisfying results:\nannot_tree$root.time \u0026lt;- max(nodeHeights(annot_tree)) + 66.0 geoscalePhylo(ladderize(annot_tree, right = F), x.lim = c(20, 240), cex.tip = 0.7, cex.age = 1.3, cex.ts = 1) T1 \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) for(i in (Ntip(annot_tree) + 1):(annot_tree$Nnode + Ntip(annot_tree))) { lines(x = c(annot_tree$min_ages[i - Ntip(annot_tree)], annot_tree$max_ages[i - Ntip(annot_tree)]), y = rep(T1$yy[i], 2), lwd = 6, lend = 0, col = make.transparent(\u0026quot;blue\u0026quot;, 0.4)) } Yes, our HPDs are clearly horrifyingly wide, but they are also not associated with the right nodes – in fact, they are not associated with any nodes, and instead just float freely over the tree. What’s going on here?\nThe answer is that the HPDs are reflected about a vertical axis in the middle of the plot. It turns out that we need to subtract both of their endpoints from the root age to fix this:\ngeoscalePhylo(ladderize(annot_tree, right = F), x.lim = c(20, 240), cex.tip = 0.7, cex.age = 1.3, cex.ts = 1) T1 \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) for(i in (Ntip(annot_tree) + 1):(annot_tree$Nnode + Ntip(annot_tree))) { lines(x = c(T1$root.time - annot_tree$min_ages[i - Ntip(annot_tree)], T1$root.time - annot_tree$max_ages[i - Ntip(annot_tree)]), y = rep(T1$yy[i], 2), lwd = 6, lend = 0, col = make.transparent(\u0026quot;blue\u0026quot;, 0.4)) } Much better!\n Putting it all together Aside from what we went over above, the function below also parameterizes at what ages to start and stop plotting (so far we’ve been using fixed values for these), automatically draws the right number of colors to highlight clades with from the good-looking viridis palette, and annotates nodes with their posterior probabilities:\nif(!require(\u0026quot;viridis\u0026quot;)) {install.packages(\u0026quot;viridis\u0026quot;)} library(viridis) beast.plotter \u0026lt;- function(basepath, clade_list, xmin, xmax) { base_tree \u0026lt;- read.nexus(paste(basepath, \u0026quot;my_MCC_tree.tre\u0026quot;, sep = \u0026quot;\u0026quot;)) annot_tree \u0026lt;- phyloch::read.beast(paste(basepath, \u0026quot;my_MCC_tree.tre\u0026quot;, sep = \u0026quot;\u0026quot;)) age_table \u0026lt;- read.table(paste(basepath, \u0026quot;age_ranges.txt\u0026quot;, sep = \u0026quot;\u0026quot;), stringsAsFactors = F) params \u0026lt;- read.table(paste(basepath, \u0026quot;loganalyser_params.txt\u0026quot;, sep = \u0026quot;\u0026quot;), header = T, stringsAsFactors = F) if (is.null(annot_tree$`CAheight_95%_HPD_MIN`)) { annot_tree$min_ages \u0026lt;- annot_tree$`height_95%_HPD_MIN` annot_tree$max_ages \u0026lt;- annot_tree$`height_95%_HPD_MAX` } else { annot_tree$min_ages \u0026lt;- annot_tree$`CAheight_95%_HPD_MIN` annot_tree$max_ages \u0026lt;- annot_tree$`CAheight_95%_HPD_MAX` } base_tree$root.time \u0026lt;- max(nodeHeights(base_tree)) base_tree$node.label \u0026lt;- round(annot_tree$posterior, 2) if (length(params$mean[params$statistic == \u0026quot;offset\u0026quot;] != 0)) { offset \u0026lt;- params$mean[params$statistic == \u0026quot;offset\u0026quot;] base_tree$root.time \u0026lt;- base_tree$root.time + offset annot_tree$min_ages \u0026lt;- annot_tree$min_ages + offset annot_tree$max_ages \u0026lt;- annot_tree$max_ages + offset } else { base_tree$root.time \u0026lt;- base_tree$root.time + 66.0 annot_tree$min_ages \u0026lt;- annot_tree$min_ages + 66.0 annot_tree$max_ages \u0026lt;- annot_tree$max_ages + 66.0 } age_mat \u0026lt;- cbind(as.numeric(age_table[,3]), as.numeric(age_table[,2])) rownames(age_mat) \u0026lt;- age_table[,1] colnames(age_mat) \u0026lt;- c(\u0026quot;FAD\u0026quot;, \u0026quot;LAD\u0026quot;) clade_cols \u0026lt;- viridis(length(clade_list), option = \u0026quot;D\u0026quot;) br_cols \u0026lt;- branch.coloring(ladderize(base_tree, right = F), clade_list, clade_cols) tip_cols \u0026lt;- tip.coloring(ladderize(base_tree, right = F), clade_list, clade_cols) geoscalePhylo(tree = ladderize(base_tree, right = F), ages = age_mat, units = c(\u0026quot;Period\u0026quot;, \u0026quot;Epoch\u0026quot;, \u0026quot;Age\u0026quot;), boxes = \u0026quot;Epoch\u0026quot;, cex.tip = 0.7, cex.age = 1.3, cex.ts = 1, width = 2, x.lim = c(xmin, xmax), edge.color = br_cols, tip.color = tip_cols) nodelabels(base_tree$node.label) T1 \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) # Get shaded bars for the HPD intervals. Credit: # http://blog.phytools.org/2017/03/error-bars-on-divergence-times-on.html for(i in (Ntip(base_tree) + 1):(base_tree$Nnode + Ntip(base_tree))) { lines(x = c(T1$root.time - annot_tree$min_ages[i - Ntip(base_tree)], T1$root.time - annot_tree$max_ages[i - Ntip(base_tree)]), y = rep(T1$yy[i], 2), lwd = 6, lend = 0, col = make.transparent(\u0026quot;blue\u0026quot;, 0.4)) } } Let’s try it out!\nbeast.plotter(\u0026quot;~/\u0026quot;, my_dino_list, 10, 240)  Refs  Bell MA, Lloyd GT 2014 strap: an R package for plotting phylogenies against stratigraphy and assessing their stratigraphic congruence. Palaeontol 58(2)2: 379–389 Heibl C 2013 http://www.christophheibl.de/Rpackages.html. Accessed 2020-01-29 Jombart T, Aanensen DM, Baguelin M, Birrell P, Cauchemez S, Camacho A, Colijn C, Collins C, Cori A, Didelot X, Fraser C, Frost S, Hens N, Hugues J, Höhle M, Opatowski L, Rambaut A, Ratmann O, Soubeyrand S, Suchard MA, Wallinga J, Ypma R, Ferguson N 2014 OutbreakTools: a new platform for disease outbreak analysis using the R software. Epidemics 7: 28–34 Schliep KP 2010 phangorn: phylogenetic analysis in R. Bioinform 27(4): 592–593   ","date":1580248800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580248800,"objectID":"bae2db8a4b3834a4e17887ab2b53016d","permalink":"/post/plotting_beast/","publishdate":"2020-01-28T22:00:00Z","relpermalink":"/post/plotting_beast/","section":"post","summary":"The summary of the posterior from a Bayesian tip-dating analysis – e.g., the maximum clade credibility tree computed by TreeAnnotator from a BEAST 2 posterior – usually provides a whole wealth of information to the user, and while barebones, quick-and-dirty plotting of the results using FigTree or plot.phylo() is good enough for assessing whether the results are reasonable or not, it definitely doesn’t provide publication-quality figures. Below, I’ll try to show how such figures can be made by combining several existing R packages.","tags":[],"title":"Visualizing BEAST 2 time trees","type":"post"},{"authors":["Matt Friedman","Kara L. Feilich","Hermione T. Beckett","Michael E. Alfaro","Brant C. Faircloth","David Černý","Masaki Miya","Thomas J. Near","Richard C. Harrington"],"categories":null,"content":"","date":1568160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568160000,"objectID":"b1f5808127743bc1610b97a099e7b2eb","permalink":"/publication/friedman_et_al_2019/","publishdate":"2019-11-23T20:45:00Z","relpermalink":"/publication/friedman_et_al_2019/","section":"publication","summary":"The fish clade Pelagiaria, which includes tunas as its most famous members, evolved remarkable morphological and ecological variety in a setting not generally considered conducive to diversification: the open ocean. Relationships within Pelagiaria have proven elusive due to short internodes subtending major lineages suggestive of rapid early divergences. Using a novel sequence dataset of over 1000 ultraconserved DNA elements (UCEs) for 94 of the 286 species of Pelagiaria (more than 70% of genera), we provide a time-calibrated phylogeny for this widely distributed clade. Some inferred relationships have clear precedents (e.g. the monophyly of ‘core’ Stromateoidei, and a clade comprising ‘Gempylidae’ and Trichiuridae), but others are unexpected despite strong support (e.g. Chiasmodontidae + *Tetragonurus*). Relaxed molecular clock analysis using node-based fossil calibrations estimates a latest Cretaceous origin for Pelagiaria, with crown-group families restricted to the Cenozoic. Estimated mean speciation rates decline from the origin of the group in the latest Cretaceous, although credible intervals for root and tip rates are broad and overlap in most cases, and there is higher-than-expected partitioning of body shape diversity (measured as fineness ratio) between clades concentrated during the Palaeocene–Eocene. By contrast, more direct measures of ecology show either no substantial deviation from a null model of diversification (diet) or patterns consistent with evolutionary constraint or high rates of recent change (depth habitat). Collectively, these results indicate a mosaic model of diversification. Pelagiarians show high morphological disparity and modest species richness compared to better-studied fish radiations in contrasting environments. However, this pattern is also apparent in other clades in open-ocean or deep-sea habitats, and suggests that comparative study of such groups might provide a more inclusive model of the evolution of diversity in fishes.\n","tags":["Vertebrate phylogenetics","Macroevolutionary patterns","Phylogenetic comparative methods","Divergence dating","UCEs"],"title":"A phylogenomic framework for pelagiarian fishes (Acanthomorpha: Percomorpha) highlights mosaic radiation in the open ocean","type":"publication"},{"authors":["David Černý","Daniel Madzia","Graham J. Slater"],"categories":null,"content":"","date":1561217400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561217400,"objectID":"c9763ef7072decc6bbbfd4f236855223","permalink":"/talk/evolution_2019/","publishdate":"2019-11-23T21:00:00Z","relpermalink":"/talk/evolution_2019/","section":"talk","summary":"A number of methods have recently become available to infer rates of speciation and extinction from datasets containing or restricted to extinct taxa; however, their comparative performance remains largely unexplored. To investigate the congruence of the estimates of macroevolutionary rates produced by these approaches, we inferred tip-dated phylogenies of bird-hipped dinosaurs (Archosauria: Ornithischia) using the Sampled-Ancestor Fossilized Birth-Death (SA-FBD) process and two of the largest character matrices published to date (73 taxa and 255 characters; 69 taxa and 380 characters). Phylogeny-based diversification rate analyses were performed using the recently released \"fossil BAMM\" (BAMM v2.6) package and a SA-FBD epoch model in BEAST 2. Importantly, no rate shifts were identified in the BAMM analyses, with the posterior probability of the zero-shift configuration ranging from 0.49 to 0.68, and ornithischian evolution was characterized by a single tree-wide density-dependent mode of diversification. Given the high congruence between the prior and posterior rate shift number distributions, we speculate that these findings may be driven by the insufficient number of included tips. A comparison with PyRate, a related Bayesian approach that does not rely on time-calibrated phylogenies, is also presented. We urge caution when applying BAMM-type macroevolutionary analyses to wholly extinct clades, as even the most comprehensive datasets available for extensively studied groups may not be large enough to detect diversification rate shifts.\n","tags":[],"title":"Inferring macroevolutionary dynamics of extinct clades: a test using ‘bird-hipped’ dinosaurs (Ornithischia)","type":"talk"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["David Černý","Kristen Lee","Jocelyn Medal","Daniel T. Blumstein"],"categories":null,"content":"","date":1545350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545350400,"objectID":"ebe99e8e5179a3a0749c387a424b30f8","permalink":"/publication/cerny_et_al_2018/","publishdate":"2019-11-23T20:30:00Z","relpermalink":"/publication/cerny_et_al_2018/","section":"publication","summary":"Lanchester’s laws of combat are a mathematical framework describing the relative contributions of individual fighting ability and group size to overall group fighting ability. Since 1993, several studies have attempted to apply this framework to interspecific dominance relationships between nonhuman animals. However, this prior work addressed only the corollaries of Lanchester’s laws rather than the laws themselves. Here, we directly test Lanchester’s linear and square law to explain interspecific competition of coral reef fish. First, we analyzed the relationship between body size and dominance to find a biologically accurate proxy of individual fighting ability. We then tested whether group fighting ability was linearly (linear law) or quadratically (square law) related to group size while accounting for the different fighting abilities of competing species. We found support for the linear law; however, both laws were outperformed by a simpler model that only included body size. After accounting for possible outliers and data limitations, we suggest that Lanchester’s linear law may prove useful for explaining interspecific competition in marine ecosystems.\n","tags":["Behavioral ecology","Phylogenetic comparative methods"],"title":"Applying Lanchester’s laws to the interspecific competition of coral reef fish","type":"publication"},{"authors":["Marcela G.M. Lima","José de Sousa e Silva-Júnior","David Černý","Janet C. Buckner","Alexandre Aleixo","Jonathan Chang","Jimmy Zheng","Michael E. Alfaro","Amely Martins","Anthony Di Fiore","Jean P. Boubli","Jessica W. Lynch Alfaro"],"categories":null,"content":"","date":1520812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520812800,"objectID":"f08dfc01de1ea99880130580321e9bc8","permalink":"/publication/lima_et_al_2018/","publishdate":"2019-11-23T20:15:00Z","relpermalink":"/publication/lima_et_al_2018/","section":"publication","summary":"Phylogenetic relationships amongst the robust capuchin monkeys (genus *Sapajus*) are poorly understood. Morphology-based taxonomies have recognized anywhere from one to twelve different species. The current IUCN (2017) classification lists eight robust capuchins: *S. xanthosternos*, *S. nigritus*, *S. robustus*, *S. flavius*, *S. libidinosus*, *S. cay*, *S. apella* and *S. macrocephalus*. Here, we assembled the first phylogenomic data set for *Sapajus* using ultra-conserved elements (UCEs) to reconstruct a capuchin phylogeny. All phylogenomic analyses strongly supported a deep divergence of *Sapajus* and *Cebus* clades within the capuchin monkeys, and provided support for *Sapajus nigritus*, *S. robustus* and *S. xanthosternos* as distinct species. However, the UCE phylogeny lumped the putative species *S. cay*, *S. libidinosus*, *S. apella*, *S. macrocephalus*, and *S. flavius* together as a single widespread lineage. A SNP phylogeny constructed from the UCE data was better resolved and recovered *S. flavius* and *S. libidinosus* as sister species; however, *S. apella*, *S. macrocephalus*, and *S. cay* individuals were recovered in two geographic clades, from northeastern and southwestern Amazon, rather than clustering by currently defined morphospecies. STRUCTURE analysis of population clustering revealed widespread admixture among *Sapajus* populations within the Amazon and even into the Cerrado and Atlantic Forest. Difficulty in assigning species by morphology may be a result of widespread population admixture facilitated through frequent movement across major rivers and even ecosystems by robust capuchin monkeys.\n","tags":["Vertebrate phylogenetics","Divergence dating","UCEs"],"title":"A phylogenomic perspective on the robust capuchin monkey (Sapajus) radiation: First evidence for extensive population admixture across South America","type":"publication"},{"authors":["Michael E. Alfaro","Brant C. Faircloth","Richard C. Harrington","Laurie Sorenson","Matt Friedman","Christine E. Thacker","Carl H. Oliveros","David Černý","Thomas J. Near"],"categories":null,"content":"","date":1520812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520812800,"objectID":"c2d56f5c03e4f472cc0f60c5f1a070a9","permalink":"/publication/alfaro_et_al_2018/","publishdate":"2019-11-23T20:00:00Z","relpermalink":"/publication/alfaro_et_al_2018/","section":"publication","summary":"The Cretaceous–Palaeogene (K--Pg) mass extinction is linked to the rapid emergence of ecologically divergent higher taxa (for example, families and orders) across terrestrial vertebrates, but its impact on the diversification of marine vertebrates is less clear. Spiny-rayed fishes (Acanthomorpha) provide an ideal system for exploring the effects of the K–Pg on fish diversification, yet despite decades of morphological and molecular phylogenetic efforts, resolution of both early diverging lineages and enormously diverse subclades remains problematic. Recent multilocus studies have provided the first resolved phylogenetic backbone for acanthomorphs and suggested novel relationships among major lineages. However, these new relationships and associated timescales have not been interrogated using phylogenomic approaches. Here, we use targeted enrichment of 1,000 ultraconserved elements in conjunction with a divergence time analysis to resolve relationships among 120 major acanthomorph lineages and provide a new timescale for acanthomorph radiation. Our results include a well-supported topology that strongly resolves relationships along the acanthomorph backbone and the recovery of several new relationships within six major percomorph subclades. Divergence time analyses also reveal that crown ages for five of these subclades, and for the bulk of the species diversity in the sixth, coincide with the K–Pg boundary, with divergences between anatomically and ecologically distinctive suprafamilial clades concentrated in the first 10 million years of the Cenozoic. ","tags":["Vertebrate phylogenetics","Divergence dating","UCEs"],"title":"Explosive diversification of marine fishes at the Cretaceous–Palaeogene boundary","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]